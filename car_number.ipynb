{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c0d87bc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Вступительный экзамен DL Advanced Весна'23. Программирование\n",
    "\n",
    "Данные взяты [отсюда](https://disk.yandex.ru/d/adjYzzNayB1pag).\n",
    "\n",
    "\n",
    "При решении задания в качестве источника использовался [следующий туториал](https://deepayan137.github.io/blog/markdown/2020/08/29/building-ocr.html). Подход, реализованный в данной работе, основан на раздельном распознавании сокращенного названия провинции (первого иероглифа в номере) и оставшейся части номера, состоящей из заглавных латинских букв и цифр.\n",
    "\n",
    "\n",
    "В данной работе подсчитыватся только доля правильных ответов по словам и по символам. CER не считалось, так как количество предсказываемых символов фиксированно и равно 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef70d31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import cv2\n",
    "import os\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "from torchvision import transforms as T\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import random\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38aa51b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"cfg.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "DIR = cfg[\"data_path\"]\n",
    "if DIR.endswith(\".zip\"):\n",
    "    DIR = DIR[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93dbf7fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Разархивирование данных\n",
    "\n",
    "# with zipfile.ZipFile(f\"{DIR}.zip\", 'r') as zf:\n",
    "#     zf.extractall(\"\")\n",
    "\n",
    "# # Выделениие валидационной выборки\n",
    "\n",
    "# os.mkdir(f\"{DIR}/val/\")\n",
    "# train_filenames = os.listdir(f\"{DIR}/train\")\n",
    "\n",
    "# train_filenames, val_filenames = train_test_split(train_filenames, test_size=0.15, shuffle=True, random_state=42)\n",
    "\n",
    "# for filename in val_filenames:\n",
    "#     os.rename(f\"{DIR}/train/{filename}\", f\"{DIR}/val/{filename}\")\n",
    "    \n",
    "# # Сжатие полученных трех выборок \n",
    "\n",
    "# with zipfile.ZipFile(f\"{DIR}.zip\", \"w\") as zf:\n",
    "#     for dirname, subdirs, files in os.walk(f\"{DIR}):\n",
    "#         zf.write(dirname)\n",
    "#         for filename in tqdm(files):\n",
    "#             zf.write(os.path.join(dirname, filename))\n",
    "\n",
    "# # Удаление разархивированного файла\n",
    "\n",
    "# for split in \"train\", \"val\", \"test\":\n",
    "#     for filename in os.listdir(f\"{DIR}/{split}\"):\n",
    "#         os.remove(f\"{DIR}/{split}/{filename}\")\n",
    "#     os.rmdir(f\"{DIR}/{split}\")\n",
    "# os.rmdir(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de95fa35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfms = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.ConvertImageDtype(torch.uint8),\n",
    "    T.CenterCrop((cfg[\"preprocess\"][\"img_height\"], cfg[\"preprocess\"][\"img_width\"])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d55e45c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Функция для выделение метки из названия файла и перевод в правильную кодировку\n",
    "\n",
    "def label_filter(name):\n",
    "    return name[name.find(\"-\", 9) + 1:-4].encode('cp437').decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80928d1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "provinces = cfg[\"provinces\"]  # список всех сокращенных названий провинций Китая\n",
    "\n",
    "vocab = [chr(idx) for idx in list(range(ord(\"A\"), ord(\"Z\") + 1)) + list(range(ord(\"0\"), ord(\"9\") + 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec402018",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "province_map = {province: idx for idx, province in enumerate(provinces)}\n",
    "symbol_map = {symbol: idx for idx, symbol in enumerate(vocab)}\n",
    "\n",
    "province_map_rev = {idx: province for idx, province in enumerate(provinces)}\n",
    "symbol_map_rev = {idx: symbol for idx, symbol in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c80255",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Класс для чтения данных из архивированного файла\n",
    "\n",
    "class ZipDataset(Dataset):\n",
    "    def __init__(self, path, label_filter=None, prefix=\"\", transform=None):\n",
    "        f = open(path, 'rb')\n",
    "        self.zip_content = f.read()\n",
    "        f.close()\n",
    "        self.zip_file = zipfile.ZipFile(io.BytesIO(self.zip_content), 'r')\n",
    "        self.label_filter = label_filter\n",
    "        self.prefix = prefix\n",
    "        self.name_list = list(filter(lambda filename: filename.endswith(\".jpg\") and filename.startswith(self.prefix),\n",
    "                              self.zip_file.namelist()))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        name = self.name_list[key]\n",
    "        buf = self.zip_file.read(name=name)\n",
    "        img = cv2.imdecode(np.frombuffer(buf, dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.label_filter:\n",
    "            name = label_filter(name)\n",
    "        return img, name\n",
    "    \n",
    "#     def collate_fn(self, key):\n",
    "        \n",
    "    # def convert_label(self, name):\n",
    "    #     if self.label_filter:\n",
    "    #         name = label_filter(name)\n",
    "    #     return province_map[name[0]], [symbol_map[symbol] for symbol in name[1:]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9ac632a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = cfg[\"training\"][\"batch_size\"]\n",
    "\n",
    "train_dataset = ZipDataset(cfg[\"data_path\"], prefix=f\"{DIR}/train\", label_filter=label_filter, transform=tfms)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = ZipDataset(cfg[\"data_path\"], prefix=f\"{DIR}/val\", label_filter=label_filter, transform=tfms)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = ZipDataset(cfg[\"data_path\"], prefix=f\"{DIR}/test\", label_filter=label_filter, transform=tfms)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2871681",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В основе реализованной в данной работе модели лежит модель из туториала.\n",
    "Изменения:\n",
    "    - Только один слой двунаправленной LSTM\n",
    "    - Добавлены полносвязные слои для сжатия по ширине и высоте\n",
    "    - Выход рекуррентного слоя разбивается на два. Первый выход преобразуется в распределение над словарем названий провинций, второй - в распределение на словарем латинских заглавных букв и цифр\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2176f2f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding_1 = nn.Linear(nHidden * 2, nOut[0])\n",
    "        self.embedding_2 = nn.Linear(nHidden * 2, nOut[1])\n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.rnn.flatten_parameters()\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        recurrent = [recurrent[0], recurrent[1:]]\n",
    "        t, b, h = recurrent[1].size()\n",
    "        t_rec = recurrent[1].view(t * b, h)\n",
    "        output = [self.embedding_1(recurrent[0]).view(1, b, -1), self.embedding_2(t_rec).view(t, b, -1)]\n",
    "        return output\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, opt, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = opt['nChannels'] if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "\n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d((2, 2), 2))\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d((2, 2), 2))\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))\n",
    "        convRelu(4, True)\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))\n",
    "        convRelu(6, True)\n",
    "        \n",
    "        self.cnn = cnn\n",
    "\n",
    "        self.rnn = BidirectionalLSTM(opt['nHidden']*2, opt['nHidden'], opt['nClasses'])\n",
    "        self.linear_h = nn.Linear(7, 1)\n",
    "        self.linear_w = nn.Linear(101, 7)\n",
    "\n",
    "    def forward(self, input):\n",
    "        conv = self.cnn(input)\n",
    "        conv = self.linear_w(conv)\n",
    "        conv = conv.permute(0, 1, 3, 2)\n",
    "        conv = self.linear_h(conv)\n",
    "        conv = conv.permute(0, 1, 3, 2)\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)\n",
    "        output = self.rnn(conv)\n",
    "        output[0] = output[0].squeeze()\n",
    "        output[1] = output[1].transpose(1,0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec2a7dc3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(cfg[\"training\"][\"device\"])\n",
    "model = CRNN(cfg[\"model\"]).to(device)\n",
    "num_criterion = nn.CTCLoss(reduction=\"mean\", zero_infinity=True)\n",
    "province_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg[\"training\"][\"lr\"])\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg[\"training\"][\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1e08046",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3b0f450fd54f9db9fad376d5521930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_val = torch.Tensor().to(dtype=torch.int8)\n",
    "for batch in tqdm(val_dataloader):\n",
    "    b_labels = torch.cat(\n",
    "    (\n",
    "        torch.LongTensor([province_map[batch[1][i][0]] for i in range(len(batch[1]))]).view(-1, 1),\n",
    "        torch.LongTensor([[symbol_map[symbol] for symbol in batch[1][i][1:]] for i in range(len(batch[1]))])\n",
    "    ), dim=1)\n",
    "    y_val = torch.cat((y_val, b_labels), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb2c8486",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b590f251ed4c4f970ad7e6fd6565be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test = torch.Tensor().to(dtype=torch.int8)\n",
    "for batch in tqdm(test_dataloader):\n",
    "    b_labels = torch.cat(\n",
    "    (\n",
    "        torch.LongTensor([province_map[batch[1][i][0]] for i in range(len(batch[1]))]).view(-1, 1),\n",
    "        torch.LongTensor([[symbol_map[symbol] for symbol in batch[1][i][1:]] for i in range(len(batch[1]))])\n",
    "    ), dim=1)\n",
    "    y_test = torch.cat((y_test, b_labels), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7d42b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = cfg[\"training\"][\"seed\"]\n",
    "\n",
    "random.seed = (seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "model.cuda()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(cfg[\"training\"][\"epochs\"]):\n",
    "    print(\"Training {} epoch\".format(epoch + 1))\n",
    "    start = time.time()\n",
    "    mean_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # if (step + 1) % 200 == 0:\n",
    "        #     duration = timedelta(seconds=int(time.time() - start))\n",
    "        #     print('Batch {:>5,}  of  {:>5,}. Loss {:.3}  Time: {:}.'.format(step + 1, len(train_dataloader), mean_loss / step, duration))\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        b_input = batch[0].to(device)\n",
    "        b_labels = torch.cat(\n",
    "            (\n",
    "                torch.LongTensor([province_map[batch[1][i][0]] for i in range(len(batch[1]))]).view(-1, 1), \n",
    "                torch.LongTensor([[symbol_map[symbol] for symbol in batch[1][i][1:]] for i in range(len(batch[1]))])\n",
    "            ), dim=1).to(device)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        province_logits, num_logits = model(b_input / 255)\n",
    "        province_logits = F.softmax(province_logits, 1)\n",
    "        num_logits = F.log_softmax(num_logits, 2).transpose(0, 1)\n",
    "        pred_sizes = (torch.ones(len(batch[0])) * 7).long().to(device)\n",
    "        \n",
    "        loss = province_criterion(province_logits, b_labels[:, 0])\n",
    "        loss += num_criterion(num_logits, b_labels[:, 1:], pred_sizes, pred_sizes)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        max_grad_norm = 0.05\n",
    "        clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        mean_loss += loss.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    mean_loss = mean_loss / len(train_dataloader)\n",
    "    \n",
    "    train_losses.append(mean_loss)\n",
    "    print(\"Mean loss: \" , mean_loss)\n",
    "    print(\"Training epoch took:\" , timedelta(seconds=int(time.time() - start)))\n",
    "    torch.save(model, cfg[\"model_path\"])\n",
    "    print()\n",
    "    print(\"Validation:\")\n",
    "    model.eval()\n",
    "\n",
    "    start = time.time()\n",
    "    predictions = torch.Tensor().to(dtype=torch.int8)\n",
    "    val_loss = 0\n",
    "\n",
    "    for batch in tqdm(val_dataloader):\n",
    "\n",
    "        b_input = batch[0].to(device)\n",
    "        b_labels = torch.cat(\n",
    "        (\n",
    "            torch.LongTensor([province_map[batch[1][i][0]] for i in range(len(batch[1]))]).view(-1, 1), \n",
    "            torch.LongTensor([[symbol_map[symbol] for symbol in batch[1][i][1:]] for i in range(len(batch[1]))])\n",
    "        ), dim=1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            province_logits, num_logits = model(b_input / 255)\n",
    "            province_logits = F.softmax(province_logits, 1)\n",
    "            num_logits = F.log_softmax(num_logits, 2).transpose(0, 1)\n",
    "            pred_sizes = (torch.ones(len(batch[0])) * 7).long().to(device)\n",
    "\n",
    "            loss = province_criterion(province_logits, b_labels[:, 0])\n",
    "            loss += num_criterion(num_logits, b_labels[:, 1:], pred_sizes, pred_sizes)\n",
    "\n",
    "        predictions = torch.cat((predictions, torch.cat((\n",
    "            province_logits.argmax(dim=1).view(-1, 1).cpu().detach(), \n",
    "            num_logits.transpose(0, 1).argmax(dim=-1).cpu().detach()\n",
    "            ), dim=1)), dim=0)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"Accuracy by word: {:4.2f}\".format(np.equal(y_val, predictions).all(axis=1).float().mean()))\n",
    "    print(\"Accuracy by char: {:4.2f}\".format(np.equal(y_val, predictions).float().mean()))\n",
    "    val_losses.append(val_loss / len(val_dataloader))\n",
    "    print(\"Validation took: {:}\".format(timedelta(seconds = int(time.time() - start))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bba34ffb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load(\"model_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "baa10e7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257c085bcce14146a92e648ef4343b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by word: 0.89\n",
      "Accuracy by char: 0.98\n",
      "Testing took: 0:00:43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing:\")\n",
    "model.eval()\n",
    "\n",
    "start = time.time()\n",
    "test_predictions = torch.Tensor().to(dtype=torch.int8)\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "\n",
    "    b_input = batch[0].to(device)\n",
    "    b_labels = torch.cat(\n",
    "    (\n",
    "        torch.LongTensor([province_map[batch[1][i][0]] for i in range(len(batch[1]))]).view(-1, 1),\n",
    "        torch.LongTensor([[symbol_map[symbol] for symbol in batch[1][i][1:]] for i in range(len(batch[1]))])\n",
    "    ), dim=1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        province_logits, num_logits = model(b_input / 255)\n",
    "        province_logits = F.softmax(province_logits, 1)\n",
    "        num_logits = F.log_softmax(num_logits, 2).transpose(0, 1)\n",
    "\n",
    "    test_predictions = torch.cat((test_predictions, torch.cat((\n",
    "        province_logits.argmax(dim=1).view(-1, 1).cpu().detach(),\n",
    "        num_logits.transpose(0, 1).argmax(dim=-1).cpu().detach()\n",
    "        ), dim=1)), dim=0)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Accuracy by word: {:4.2f}\".format(np.equal(y_test, test_predictions).all(axis=1).float().mean()))\n",
    "print(\"Accuracy by char: {:4.2f}\".format(np.equal(y_test, test_predictions).float().mean()))\n",
    "print(\"Testing took: {:}\".format(timedelta(seconds = int(time.time() - start))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0283f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}